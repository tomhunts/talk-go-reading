## 19-20 | 案例篇：为什么系统的Swap变高了

### 内存回收

+ 文件页：即内存中的数据来自于相应的文件，则这部分只需要将内存中的数据写入到文件中，即可释放，这些脏页写入文件一般通过两种方式：在应用程序中调用fsync，把脏页同步到磁盘中，或者交由系统，由内核线程pdflush负责这些脏页的刷新。
+ 匿名页： 此部分属于应用程序动态分配的堆内存，主要通过swap机制，把不常访问的内存先写入到磁盘中，然后释放内存

### Swap 原理

+ 换出：将进程暂时不用的内存数据存储到磁盘中，并释放这些数据占用的内存
+ 换入：进程再次访问这些内存的时候，将他们从磁盘读到内存中

我们常见的笔记本电脑的休眠和快速开机功能也是基于swap的

内存回收的方式：
+ 直接内存回收：有新的大块内存分配请求，但剩余内存不足时
+ 专门的内核线程来定期回收内存：也就是kswapd0

衡量内存能使用情况，kswapd0定义了三个内存阈值，分别为页最小阈值（pages_min）、页低阈值（pages_low）和页高阈值（pages_high）。剩余内存，则使用 pages_free。

#### 内核线程回收内存的方式

通过剩余内存落在三个阈值的空间位置来进程回收操作
+ 剩余内存小于页最小阈值：说明进程可用内存都用尽了，至于内核才可以分配内存
+ 剩余内存在页最小阈值和页低阈值中间：说明内存压力比较大，剩余内存不多了，这时kswapd0会执行内存回收，直到剩余内存大于高阈值为止
+ 剩余内存在页低阈值和页高阈值中间：说明内存由一定压力，但可满足新内存申请
+ 剩余内存大于高阈值L说明剩余内存比较多，没有内存压力

设置页低阈值的方式：/proc/sys/vm/min_free_kbytes文件，其他两个阈值的方式为
pages_low = pages_min*5/4
pages_high = page_min*3/2

#### NUMA架构

NUMA架构会导致有时剩余内存还很多时，依然发生swap

NUMA架构：多个处理器被划分到不同Node上，且每个node都有自己的本地内存空间，同一个Node内部的内存空间，实际又可以进一步被分为不同的内存域，比如：直接内存访问区（DMA），普通内存区（NORMAL），伪内存区（MOVABLE）等

通过numactl命令查看处理器在node的分布情况

```sh
root@devops-064167:/home/hero# numactl  --hardware
available: 1 nodes (0)
node 0 cpus: 0 1 2 3 4 5 6 7
node 0 size: 8191 MB
node 0 free: 581 MB
node distances:
node   0
  0:  10
```
我的系统只有一个Node，编号0到7一共8个cpu都在node0上，内存代销为8192MB，剩余582MB

通过内存域在proc文件系统中的接口/proc/zoneinfo来查看三个内存阈值

```sh
root@devops-064167:/home/hero# cat /proc/zoneinfo
Node 0, zone      DMA
  pages free     3977
        min      33
        low      41
        high     49
        scanned  0
        spanned  4095
        present  3998
        managed  3977
    nr_free_pages 3977
    nr_alloc_batch 8
    nr_inactive_anon 0
    nr_active_anon 0
    nr_inactive_file 0
    nr_active_file 0
    nr_unevictable 0
    nr_mlock     0
    nr_anon_pages 0
    nr_mapped    0
    nr_file_pages 0
    ....
```
+ pages处的min,low,high就是上面提到的三个内存阈值
+ nr_zone_active_anon和nr_zone_inactive_anon分别是活跃和非活跃的匿名页数
+ nr_zone_active_file和nr_zone_inactive_file分别是活跃和非活跃的文件页数

在内存不足时，系统可从其他Node寻找空间内存也可以从本地内存中回收内存，具体选那种模式通过/proc/sys/vm/zone_reclaim_mode来调整
+ 默认0:既可以从其他Node寻找空闲内存，也可以从本地回收内存
+ 1，2，4 都表示只回收本地内存，2表示可以回写脏数据回收内存，4表示可使用swap方式回收内存

调整内存不足时，通过匿名页回收还是文件页的回收权重：/proc/sys/vm/seappiness
+ swappiness的范围是0-100,数值越大，越积极使用Swap，也就是更倾向于回收匿名页，数值越小，越消极使用Swap，更倾向于回收文件页，这里仅仅是配置权重，等0，或者100并不代表就放弃另一个的回收，只是权重更大而已


### 内存回收的3种调优策略配置

+ /proc/sys/vm/min_free_kbytes 调整系统定期回收内存的阈值
+ /proc/sys/vm/swappiness 调整文件页和匿名页的回收倾向
+ /proc/sys/vm/zone_reclaim_mode 调整NUMA本地内存的回收策略
+ 如果linux内核是3.5及以后的，最好是设置swappiness=10.不要设置swappiness=0
+ swap清理的常用方式：关闭再打开


### Swap案例


#### 开启swap

linux本身支持两种类型的Swap，即Swap分区和Swap文件，下面以文件为例：

```sh

# 创建Swap文件
$ fallocate -l 8G /mnt/swapfile
# 修改权限只有根用户可以访问
$ chmod 600 /mnt/swapfile
# 配置Swap文件
$ mkswap /mnt/swapfile
# 开启Swap
$ swapon /mnt/swapfile
# 关闭Swap
$ swapoff -a
```

#### 使用dd模拟大文件读取

```sh
# 写入空设备，实际上只有磁盘的读请求
$ dd if=/dev/sda1 of=/dev/null bs=1G count=2048
```


使用sar命令观察内存使用情况

```sh
# 间隔1秒输出一组数据
# -r表示显示内存使用情况，-S表示显示Swap使用情况
root@devops-064167:/home/hero# sar -r -S 1
Linux 3.10.0-327.el7.x86_64 (devops-064167.tst.vm.tjcn2.bmsre.com) 	06/15/2020 	_x86_64_	(8 CPU)

04:36:27 PM kbmemfree kbmemused  %memused kbbuffers  kbcached  kbcommit   %commit  kbactive   kbinact   kbdirty
04:36:28 PM    643764   7366692     91.96      1292   4256608   6369504     79.51   4343884   2298300        40
```

+ kbcommit:当前系统负载需要的内存，它实际上是为了保证系统内存不溢出，对需要内存的估计值，%commit是这个值对总内存的百分比
+ kbactive:表示活跃内存，最近使用过的内存，一般不会被系统回收
+ kbinact: 表示非活跃内存，不常访问的内存，有可能被系统回收

#### 分析过程

+ 通过sar命令看到内存使用率%memused不断增长，而且缓冲区占用了大部分内存，这是Swap的使用开始逐渐增大，缓冲区和剩余内存在小范围波动
+ 通过cachetop查看进程缓存情况：可以看到具体导致缓冲区升高的命令
+ 通过/proc/zoneinfo观察剩余内存，内存阈值以及匿名页和文件页的活跃情况：发现剩余内存在小范围不停波动，低于页最低阈值时，又会突然增大到一个大于页高阈值的值，这里正是由于内存的回收导致的
	+ 当剩余内存小于页最低阈值时，系统会回收一些缓存和匿名内存，使剩余内存增大，其中，缓存的回收导致sar中的缓冲区减小，匿名内存回收导致Swap使用增大
	+ dd还在继续，剩余内存又会重新分配给缓存，导致剩余内存减少，缓冲区增大

+ 通过/proc/pid/status中的VmsSwap保存了Swap换出的虚拟内存大小，以及相应的进程


### 拓展

+ smem --sort swap 命令可以直接将进程按照swap使用量排序显示

